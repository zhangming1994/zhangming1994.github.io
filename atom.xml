<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>赵客缦胡缨，吴钩霜雪明</title>
  
  
  <link href="http://zhangming1994.github.io/atom.xml" rel="self"/>
  
  <link href="http://zhangming1994.github.io/"/>
  <updated>2023-08-24T03:27:44.173Z</updated>
  <id>http://zhangming1994.github.io/</id>
  
  <author>
    <name>铁马冰河</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Golang内存管理-垃圾回收</title>
    <link href="http://zhangming1994.github.io/2023/08/24/Golang%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <id>http://zhangming1994.github.io/2023/08/24/Golang%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</id>
    <published>2023-08-24T03:23:24.000Z</published>
    <updated>2023-08-24T03:27:44.173Z</updated>
    
    <content type="html"><![CDATA[<p>Golang 内存管理（四）：垃圾回收</p><p>Golang gc发展进程</p><p>1.1 版本: 标记+清除方式，整个过程需要 STW(stop the world，挂起所有用户 goroutine)<br>1.3 版本: 标记过程 STW，清除过程并行<br>1.5 版本: 标记过程使用三色标记法<br>1.8 版本: Hibrid Write Barrier</p><p>标记清除</p><p>垃圾回收的算法很多，比如最常见的引用计数，节点复制等等。Go 采用的是标记清除方式。当 GC 开始时，从 root 开始一层层扫描，这里的 root 区值当前所有 goroutine 的栈和全局数据区的变量(主要是这 2 个地方)。扫描过程中把能被触达的 object 标记出来，那么堆空间未被标记的 object 就是垃圾了；最后遍历堆空间所有 object 对垃圾（未标记）的 object 进行清除，清除完成则表示 GC 完成。清除的 object 会被放回到 mcache 中以备后续分配使用</p><p>Go 的内存mheap区域中有一个 bitmap 区域，就是用来存储 object 标记的 </p><p>最开始 Go 的整个 GC 过程需要 STW，因为用户进程如果在 GC 过程中修改了变量的引用关系，可能会导致清理错误</p><p>并行清除</p><p>这个优化很简单，如上面所述，STW 是为了阻止标记的错误，那么只需对标记过程进行 STW，确保标记正确。清除过程是不需要 STW 的。<br>标记清除算法致命的缺点就在 STW 上，所以 Golang 后期的很多优化都是针对 STW 的，尽可能缩短它的时间，避免出现 Go 服务的卡顿。</p><p>三色标记法<br>为了能让标记过程也能并行，Go 采用了三色标记 + 写屏障的机制。它的步骤大致如下</p><ol><li>GC 开始时，认为所有 object 都是白色，即垃圾。</li><li>从 root 区开始遍历，被触达的 object 置成灰色。</li><li>遍历所有灰色 object，将他们内部的引用变量置成 灰色，自身置成 黑色</li><li>循环第 3 步，直到没有灰色 object 了，只剩下了黑白两种，白色的都是垃圾。</li><li>对于黑色 object，如果在标记期间发生了写操作，写屏障会在真正赋值前将新对象标记为灰色。</li><li>标记过程中，mallocgc 新分配的 object，会先被标记成黑色再返回。</li></ol><p>￼<img src="/img/golang/garbge1.png"></p><p>还有一种情况，标记过程中，堆上的 object 被赋值给了一个栈上指针，导致这个 object 没有被标记到。因为对栈上指针进行写入，写屏障是检测不到的。</p><p>￼￼<img src="/img/golang/garbge2.png"></p><p>为了解决这个问题，标记的最后阶段，还会回头重新扫描一下所有的栈空间，确保没有遗漏。而这个过程就需要启动 STW 了，否则并发场景会使上述场景反复重现</p><p>整个 GC 流程如下图所示：<br>￼<br>￼<img src="/img/golang/garbge3.png"></p><p>正常情况下，写操作就是正常的赋值。<br>GC 开始，开启写屏障等准备工作。开启写屏障等准备工作需要短暂的 STW。<br>Stack scan 阶段，从全局空间和 goroutine 栈空间上收集变量。<br>Mark 阶段，执行上述的三色标记法，直到没有灰色对象。<br>Mark termination 阶段，开启 STW，回头重新扫描 root 区域新变量，对他们进行标记。<br>Sweep 阶段，关闭 STW 和 写屏障，对白色对象进行清除。</p><p>Hibrid Write Barrier：</p><p>三色标记方式，需要在最后重新扫描一下所有全局变量和 goroutine 栈空间，如果系统的 goroutine 很多，这个阶段耗时也会比较长，甚至会长达 100ms。毕竟 Goroutine 很轻量，大型系统中，上百万的 Goroutine 也是常有的事儿。<br>上面说对栈上指针进行写入，写屏障是检测不到，实际上并不是做不到，而是代价非常高，Go 的写屏障故意没去管它，而是采取了再次扫描的方案<br>Go 在 1.8 版本引入了混合写屏障，其会在赋值前，对旧数据置灰，再视情况对新值进行置灰</p><p>￼<br>￼<img src="/img/golang/garbge4.png"></p><p>何时触发 GC</p><ol><li>一般是当 Heap 上的内存达到一定数值后，会触发一次 GC，这个数值我们可以通过环境变量 GOGC 或者 debug.SetGCPercent() 设置，默认是 100，表示当内存增长 100% 执行一次 GC。如果当前堆内存使用了 10MB，那么等到它涨到 20MB 的时候就会触发 GC。</li><li>再就是每隔 2 分钟，如果期间内没有触发 GC，也会强制触发一次。</li><li>最后就是用户手动触发了，也就是调用 runtime.GC() 强制触发一次</li></ol><p>对于 tiny 对象，标记阶段是直接标记成黑色了，没有灰色阶段。因为 tiny 对象是不存放引用类型数据（指针）的，没必要标记成灰色再检查一遍。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Golang 内存管理（四）：垃圾回收&lt;/p&gt;
&lt;p&gt;Golang gc发展进程&lt;/p&gt;
&lt;p&gt;1.1 版本: 标记+清除方式，整个过程需要 STW(stop the world，挂起所有用户 goroutine)&lt;br&gt;1.3 版本: 标记过程 STW，清除过程并行&lt;br</summary>
      
    
    
    
    <category term="Golang" scheme="http://zhangming1994.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://zhangming1994.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>Golang内存管理(二)</title>
    <link href="http://zhangming1994.github.io/2023/08/24/Golang%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E4%BA%8C/"/>
    <id>http://zhangming1994.github.io/2023/08/24/Golang%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E4%BA%8C/</id>
    <published>2023-08-24T03:11:05.000Z</published>
    <updated>2023-08-24T03:34:18.932Z</updated>
    
    <content type="html"><![CDATA[<p>Go 的内存管理基本上参考 tcmalloc 来实现的， Go 的内存是自动管理的，我们可以随意定义变量直接使用，不需要考虑变量背后的内存申请和释放的问题</p><p>池<br>程序动态申请内存空间，是要使用系统调用的，比如 Linux 系统上是调用 mmap 方法实现的。但对于大型系统服务来说，直接调用 mmap 申请内存，会有一定的代价：</p><ol><li>系统调用会导致程序进入内核态，内核分配完内存后（也就是上篇所讲的，对虚拟地址和物理地址进行映射等操作），再返回到用户态。</li><li>频繁申请很小的内存空间，容易出现大量内存碎片，增大操作系统整理碎片的压力。</li><li>为了保证内存访问具有良好的局部性，开发者需要投入大量的精力去做优化，这是一个很重的负担</li></ol><p>对象池：</p><ol><li>不需要频繁申请内存了，而是从对象池里拿，程序不会频繁进入内核态</li><li>因为一次性申请一个连续的大空间，对象池会被重复利用，不会出现碎片。</li><li>程序频繁访问的就是对象池背后的同一块内存空间，局部性良好。</li></ol><p>这样做会造成一定的内存浪费，我们可以定时检测对象池的大小，保证可用对象的数量在一个合理的范围，少了就提前申请，多了就自动释放。<br>如果某种资源的申请和回收是昂贵的，我们都可以通过建立资源池的方式来解决，其他比如连接池，内存池等等，都是一个思路</p><p>Golang 内存管理<br>Golang 的内存管理本质上就是一个内存池，只不过内部做了很多的优化。比如自动伸缩内存池大小，合理的切割内存块等等。</p><p>内存池 mheap<br>Golang 的程序在启动之初，会一次性从操作系统那里申请一大块内存作为内存池。这块内存空间会放在一个叫 mheap 的 struct 中管理，mheap 负责将这一整块内存切割成不同的区域，并将其中一部分的内存切割成合适的大小，分配给用户使用。</p><p>page: 内存页，一块 8K 大小的内存空间。Go 与操作系统之间的内存申请和释放，都是以 page 为单位的。<br>span: 内存块，一个或多个连续的 page 组成一个 span。<br>sizeclass: 空间规格，每个 span 都带有一个 sizeclass，标记着该 span 中的 page 应该如何使用<br>object: 对象，用来存储一个变量数据内存空间，一个 span 在初始化时，会被切割成一堆等大的 object。假设 object 的大小是 16B，span 大小是 8K，那么就会把 span 中的 page 就会被初始化 8K &#x2F; 16B &#x3D; 512 个 object。所谓内存分配，就是分配一个 object 出去。</p><p>Page—span—</p><p><img src="/img/golang/storage6.png"><br>￼<br>￼<br>不同span的sizeclass不同 那么里面的page就会按照不同的规格切割成等大的object用作分配<br>Go1.17.2 测试初始堆内存大约是 3866624byte [字节 1byte&#x3D;8bit 1byte&#x3D;1B 1KB&#x3D;1024B 1MB&#x3D;1024KB]  就是3776KB</p><p>内部的整体内存布局如下图所示</p><p><img src="/img/golang/storage7.png"></p><p>图中的空间大小，是 Go 向操作系统申请的虚拟内存地址空间，操作系统会将该段地址空间预留出来不做它用；而不是真的创建出这么大的虚拟内存，在页表中创建出这么大的映射关系</p><p>mheap.spans：用来存储 page 和 span 信息，比如一个 span 的起始地址是多少，有几个 page，已使用了多大等等。<br>mheap.bitmap 存储着各个 span 中对象object的标记信息，比如对象是否可回收等等。<br>mheap.arena_start: 将要分配给应用程序使用的空间。</p><p>mcentral<br>用途相同的span将会以链表的形式组织在一起 这里的用途用sizeclass来表示 就是指这个span用来存储哪种大小的对象 ，sizeclass 1.5版本共67种<br>￼<br><img src="/img/golang/storage8.png"></p><p>找到合适的span之后 会从中取出一个object返回给上层使用 这些span被放在一个叫做mcentral的结构中间管理<br>Mheap会将从os那里申请过来的内存初始化成一个大的Span(sizeclass&#x3D;0) 然后根据需要从这个大的span切分出小的span 放在mcentral中间管理 大的span由mheap.freelarge和mheap.busylarge来管理 如果mcentral中间span不够了 就从mheap.freelarge拿 这里不够就再从os申请内存 </p><p>type mheap struct {<br>    lock      mutex<br>    free      [_MaxMHeapList]mspan &#x2F;&#x2F; free lists of given length， 1M 以下<br>    freelarge mspan                &#x2F;&#x2F; free lists length &gt;&#x3D; _MaxMHeapList, &gt;&#x3D; 1M<br>    busy      [_MaxMHeapList]mspan &#x2F;&#x2F; busy lists of large objects of given length<br>    busylarge mspan                &#x2F;&#x2F; busy lists of large objects length &gt;&#x3D; _MaxMHeapList</p><pre><code>central [_NumSizeClasses]struct &#123;     // _NumSizeClasses = 67    mcentral mcentral&#125;</code></pre><p>}</p><p>type mcentral struct {<br>    lock      mutex &#x2F;&#x2F; 分配时需要加锁 避免并发情况下 多个协程同时申请内存 导致的冲突  但是 这个也会使得内存申请成为整个系统的瓶颈<br>    sizeclass int32 &#x2F;&#x2F; 哪种 sizeclass<br>    nonempty  mspan &#x2F;&#x2F; 还有可用的空间的 span 链表<br>    empty     mspan &#x2F;&#x2F; 没有可用的空间的 span 列表<br>}</p><p>这种方式可以避免出现外部碎片（文章最后面有外部碎片的介绍），因为同一个 span 是按照固定大小分配和回收的，不会出现不可利用的一小块内存把内存分割掉。这个设计方式与现代操作系统中的伙伴系统有点类似。</p><p> mcache</p><p>mcentral中间的锁会成为系统瓶颈。所以mcentral的前面又增加了一层mcache ，每一个mcache和每一个处理器(P) 对应  也就是说每一个P 都有一个mcache成员 goroutine申请内存的时候 首先从p所有的mcache中间分配 如果mcache中间没有可用的span 再从mcentral中间获取 并且填充到mcache中间 从mcache上分配内存是不需要加锁的 因为同一时间 一个p只有一个协程在上面运行 不可能出现竞争 没有锁的限制 加速了内存分配 </p><p>所以整体的内存分配模型大致如下图所示：</p><p>￼<br><img src="/img/golang/storage9.png"></p><p>其他优化：<br>有一些对象所需要的内存大小是0 如struct{} 这种类型的数据不需要内存 所以不会走上面的逻辑 系统会返回一个固定的地址  0x1180f88</p><p>Tiny对象：就是微小对象<br>上面提到的 sizeclass&#x3D;1 的 span，用来给 &lt;&#x3D; 8B 的对象使用，所以像 int32, byte, bool 以及小字符串等常用的微小对象，都会使用 sizeclass&#x3D;1 的 span，但分配给他们 8B 的空间，大部分是用不上的。并且这些类型使用频率非常高，就会导致出现大量的内部碎片。<br>所以 Go 尽量不使用 sizeclass&#x3D;1 的 span， 而是将 &lt; 16B 的对象为统一视为 tiny 对象(tinysize)。分配时，从 sizeclass&#x3D;2 的 span 中获取一个 16B 的 object 用以分配。如果存储的对象小于 16B，这个空间会被暂时保存起来 (mcache.tiny 字段)，下次分配时会复用这个空间，直到这个 object 用完为止</p><p>￼<img src="/img/golang/storage10.png"></p><p>如果要存储的数据里有指针，即使 &lt;&#x3D; 8B 也不会作为 tiny 对象对待，而是正常使用 sizeclass&#x3D;1 的 span。</p><p>大对象:<br>最大的 sizeclass 最大只能存放 32K 的对象。如果一次性申请超过 32K 的内存，系统会直接绕过 mcache 和 mcentral，直接从 mheap 上获取，mheap 中有一个 freelarge 字段管理着超大 span。</p><p>内存释放:<br>内存释放的过程就是分配的反过程 当mcache存在很多的空闲span的时候就会归还给mcentral mcentral存在很多空闲span就会归还给mheap<br>Mheap再归还给系统 </p><ol><li><p>内存分配主要在用户态完成 不需要频繁进入内核态</p></li><li><p>每个p都有独立的span cache 多个cpu不会并发读写同一块内存 减少cpu L1 cache的cacheline出现dirty的情况 增加cpu cache命中率</p></li><li><p>内存碎片问题 是自己在用户态管理的 在操作系统层是没有碎片的 使得操作系统堆碎片的管理塔里降低</p></li><li><p>Mcache的存在使得内存分配不需要加锁 增加了分配速度 </p></li><li><p>代价就是需要预先申请大块内存</p></li></ol><p>￼<img src="/img/golang/storage11.png"></p><p>将有限的计算机资源布局呈金字塔结构 再将数据从热到冷分为几个层级 放置在金字塔结构上 调度器不断调整 将热数据放在顶层 冷数据放在塔底层 </p><p>这种设计利用了计算的局部性特征，认为冷热数据的交替是缓慢的。所以最怕的就是，数据访问出现冷热骤变。在操作系统上我们称这种现象为内存颠簸，系统架构上通常被说成是缓存穿透。其实都是一个意思，就是过度的使用了金字塔低端的资源。</p><p>内存碎片：<br>内存碎片是系统在内存管理过程中，会不可避免的出现一块块无法被使用的内存空间，这是内存管理的产物。</p><p>内部碎片：<br>一般都是因为字节对齐，如上面介绍 Tiny 对象分配的部分；为了字节对齐，会导致一部分内存空间直接被放弃掉，不做分配使用。<br>再比如申请 28B 大小的内存空间，系统会分配 32B 的空间给它，这也导致了其中 4B 空间是被浪费掉的。这就是内部碎片</p><p>外部碎片：<br>一般是因为内存的不断分配释放，导致一些释放的小内存块分散在内存各处，无法被用以分配。</p><p>￼<br><img src="/img/golang/storage12.png"></p><p>源代码调用流程图：<br>￼<br><img src="/img/golang/storage13.png"></p><p>runtime.MemStats 部分注释</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">type MemStats struct &#123;</span><br><span class="line">        // heap 分配出去的字节总数，和 HeapAlloc 值相同</span><br><span class="line">        Alloc uint64</span><br><span class="line"></span><br><span class="line">        // TotalAlloc 是 heap 累计分配出去字节数，每次分配</span><br><span class="line">        // 都会累加这个值，但是释放时候不会减少</span><br><span class="line">        TotalAlloc uint64</span><br><span class="line"></span><br><span class="line">        // Sys 是指程序从 OS 那里一共申请了多少内存</span><br><span class="line">        // 因为除了 heap，程序栈及其他内部结构都使用着从 OS 申请过来的内存</span><br><span class="line">        Sys uint64</span><br><span class="line"></span><br><span class="line">        // Mallocs heap 累积分配出去的对象数</span><br><span class="line">        // 活动中的对象总数，即是 Mallocs - Frees</span><br><span class="line">        Mallocs uint64</span><br><span class="line">       </span><br><span class="line">        // Frees 值 heap 累积释放掉的对象总数</span><br><span class="line">        Frees uint64</span><br><span class="line"></span><br><span class="line">        // HeapAlloc 是分配出去的堆对象总和大小，单位字节</span><br><span class="line">        // object 的声明周期是 待分配 -&gt; 分配使用 -&gt; 待回收 -&gt; 待分配</span><br><span class="line">        // 只要不是待分配的状态，都会加到 HeapAlloc 中</span><br><span class="line">        // 它和 HeapInuse 不同，HeapInuse 算的是使用中的 span，</span><br><span class="line">        // 使用中的 span 里面可能还有很多 object 闲置</span><br><span class="line">        HeapAlloc uint64</span><br><span class="line"></span><br><span class="line">        // HeapSys 是 heap 从 OS 那里申请来的堆内存大小，单位字节</span><br><span class="line">        // 指的是虚拟内存的大小，不是物理内存，物理内存大小 Go 语言层面是看不到的。</span><br><span class="line">        // 等于 HeapIdle + HeapInuse</span><br><span class="line">        HeapSys uint64</span><br><span class="line"></span><br><span class="line">        // HeapIdle 表示所有 span 中还有多少内存是没使用的</span><br><span class="line">        // 这些 span 上面没有 object，也就是完全闲置的，可以随时归还给 OS</span><br><span class="line">        // 也可以用于堆栈分配</span><br><span class="line">        HeapIdle uint64</span><br><span class="line"></span><br><span class="line">        // HeapInuse 是处在使用中的所有 span 中的总字节数</span><br><span class="line">        // 只要一个 span 中有至少一个对象，那么就表示它被使用了</span><br><span class="line">        // HeapInuse - HeapAlloc 就表示已经被切割成固定 sizeclass 的 span 里</span><br><span class="line">        HeapInuse uint64</span><br><span class="line"></span><br><span class="line">        // HeapReleased 是返回给操作系统的物理内存总数</span><br><span class="line">        HeapReleased uint64</span><br><span class="line"></span><br><span class="line">        // HeapObjects 是分配出去的对象总数</span><br><span class="line">        // 如同 HeapAlloc 一样，分配时增加，被清理或被释放时减少</span><br><span class="line">        HeapObjects uint64</span><br><span class="line"></span><br><span class="line">        // NextGC is the target heap size of the next GC cycle.</span><br><span class="line">        // NextGC 表示当 HeapAlloc 增长到这个值时，会执行一次 GC</span><br><span class="line">        // 垃圾回收的目标是保持 HeapAlloc ≤ NextGC，每次 GC 结束</span><br><span class="line">        // 下次 GC 的目标，是根据当前可达数据和 GOGC 参数计算得来的</span><br><span class="line">        NextGC uint64</span><br><span class="line"></span><br><span class="line">        // LastGC 是最近一次垃圾回收结束的时间 (the UNIX epoch).</span><br><span class="line">        LastGC uint64</span><br><span class="line"></span><br><span class="line">        // PauseTotalNs 是自程序启动起， GC 造成 STW 暂停的累积纳秒值</span><br><span class="line">        // STW 期间，所有的 goroutine 都会被暂停，只有 GC 的 goroutine 可以运行</span><br><span class="line">        PauseTotalNs uint64</span><br><span class="line"></span><br><span class="line">        // PauseNs 是循环队列，记录着 GC 引起的 STW 总时间</span><br><span class="line">        //</span><br><span class="line">        // 一次 GC 循环，可能会出现多次暂停，这里每项记录的是一次 GC 循环里多次暂停的综合。</span><br><span class="line">        // 最近一次 GC 的数据所在的位置是 PauseNs[NumGC%256]</span><br><span class="line">        PauseNs [256]uint64</span><br><span class="line"></span><br><span class="line">        // PauseEnd 是一个循环队列，记录着最近 256 次 GC 结束的时间戳，单位是纳秒。</span><br><span class="line">        //</span><br><span class="line">        // 它和 PauseNs 的存储方式一样。一次 GC 可能会引发多次暂停，这里只记录一次 GC 最后一次暂停的时间</span><br><span class="line">        PauseEnd [256]uint64</span><br><span class="line"></span><br><span class="line">        // NumGC 指完成 GC 的次数</span><br><span class="line">        NumGC uint32</span><br><span class="line"></span><br><span class="line">        // NumForcedGC 是指应用调用了 runtime.GC() 进行强制 GC 的次数</span><br><span class="line">        NumForcedGC uint32</span><br><span class="line"></span><br><span class="line">        // BySize 统计各个 sizeclass 分配和释放的对象的个数</span><br><span class="line">        //</span><br><span class="line">        // BySize[N] 统计的是对象大小 S，满足 BySize[N-1].Size &lt; S ≤ BySize[N].Size 的对象</span><br><span class="line">        // 这里不记录大于 BySize[60].Size 的对象分配</span><br><span class="line">        BySize [61]struct &#123;</span><br><span class="line">                // Size 表示该 sizeclass 的每个对象的空间大小</span><br><span class="line">                // size class.</span><br><span class="line">                Size uint32</span><br><span class="line"></span><br><span class="line">                // Mallocs 是该 sizeclass 分配出去的对象的累积总数</span><br><span class="line">                // Size * Mallocs 就是累积分配出去的字节总数</span><br><span class="line">                // Mallocs - Frees 就是当前正在使用中的对象总数</span><br><span class="line">                Mallocs uint64</span><br><span class="line"></span><br><span class="line">                // Frees 是该 sizeclass 累积释放对象总数</span><br><span class="line">                Frees uint64</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Go 的内存管理基本上参考 tcmalloc 来实现的， Go 的内存是自动管理的，我们可以随意定义变量直接使用，不需要考虑变量背后的内存申请和释放的问题&lt;/p&gt;
&lt;p&gt;池&lt;br&gt;程序动态申请内存空间，是要使用系统调用的，比如 Linux 系统上是调用 mmap 方法实现的</summary>
      
    
    
    
    <category term="Golang" scheme="http://zhangming1994.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://zhangming1994.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>Golang内存管理(一)</title>
    <link href="http://zhangming1994.github.io/2023/08/24/Golang%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86(%E4%B8%80)/"/>
    <id>http://zhangming1994.github.io/2023/08/24/Golang%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86(%E4%B8%80)/</id>
    <published>2023-08-24T02:58:50.000Z</published>
    <updated>2023-08-24T03:27:46.838Z</updated>
    
    <content type="html"><![CDATA[<p>可以把内存看成一个数组，每个数组元素的大小是 1B，也就是 8 位(bit)。CPU 通过内存地址来获取内存中的数据，内存地址可以看做成数组的游标（index）</p><p>￼<img src="/img/storage1.png"><br>￼<br>CPU 在执行指令的时候，就是通过内存地址，将物理内存上的数据载入到寄存器，然后执行机器指令,但随着发展，出现了多任务的需求，也就是希望多个任务能同时在系统上运行。这就出现了一些问题:<br>内存访问冲突：程序很容易出现 bug，就是 2 或更多的程序使用了同一块内存空间，导致数据读写错乱，程序崩溃。更有一些黑客利用这个缺陷来制作病毒。<br>内存不够用：因为每个程序都需要自己单独使用的一块内存，内存的大小就成了任务数量的瓶颈。<br>程序开发成本高：你的程序要使用多少内存，内存地址是多少，这些都不能搞错，对于人来说，开发正确的程序很费脑子。</p><p>虚拟内存<br>虚拟内存的出现，很好的为了解决上述的一些列问题。用户程序只能使用虚拟的内存地址来获取数据，系统会将这个虚拟地址翻译成实际的物理地址<br>对于内存不够用的问题，虚拟内存本质上是将磁盘当成最终存储，而主存作为了一个 cache。程序可以从虚拟内存上申请很大的空间使用，比如 1G；但操作系统不会真的在物理内存上开辟 1G 的空间，它只是开辟了很小一块，比如 1M 给程序使用。这样程序在访问内存时，操作系统看访问的地址是否能转换成物理内存地址。能则正常访问，不能则再开辟。这使得内存得到了更高效的利用。<br>如下图所示，每个进程所使用的虚拟地址空间都是一样的，但他们的虚拟地址会被映射到主存上的不同区域，甚至映射到磁盘上（当内存不够用时）。</p><p>￼￼<img src="/img/storage2.png"></p><p>其实本质上很简单，就是操作系统将程序常用的数据放到内存里加速访问，不常用的数据放在磁盘上。这一切对用户程序来说完全是透明的，用户程序可以假装所有数据都在内存里，然后通过虚拟内存地址去访问数据。在这背后，操作系统会自动将数据在主存和磁盘之间进行交换。</p><p>虚拟地址翻译<br>虚拟内存的实现方式，大多数都是通过页表来实现的。操作系统虚拟内存空间分成一页一页的来管理，每页的大小为 4K（当然这是可以配置的，不同操作系统不一样）。磁盘和主内存之间的置换也是以页为单位来操作的。4K 算是通过实践折中出来的通用值，太小了会出现频繁的置换，太大了又浪费内存。</p><p>虚拟地址 -&gt; 物理地址 的映射关系由页表（Page Table）记录，它其实就是一个数组，数组中每个元素叫做页表条目（Page Table Entry，简称 PTE），PTE 由一个有效位和 n 位地址字段构成，有效位标识这个虚拟地址是否分配了物理内存。</p><p>页表被操作系统放在物理内存的指定位置，CPU 上有个 Memory Management Unit（MMU） 单元，CPU 把虚拟地址给 MMU，MMU 去物理内存中查询页表，得到实际的物理地址。当然 MMU 不会每次都去查的，它自己也有一份缓存叫Translation Lookaside Buffer (TLB)，是为了加速地址翻译</p><p>￼<br>￼<img src="/img/storage3.png"></p><p>让我们来看一下 CPU 内存访问的完整过程：</p><ol><li>CPU 使用虚拟地址访问数据，比如执行了 MOV 指令加载数据到寄存器，把地址传递给 MMU。</li><li>MMU 生成 PTE 地址，并从主存（或自己的 Cache）中得到它。</li><li>如果 MMU 根据 PTE 得到真实的物理地址，正常读取数据。流程到此结束。</li><li>如果 PTE 信息表示没有关联的物理地址，MMU 则触发一个缺页异常。</li><li>操作系统捕获到这个异常，开始执行异常处理程序。在物理内存上创建一页内存，并更新页表。</li><li>缺页处理程序在物理内存中确定一个牺牲页，如果这个牺牲页上有数据，则把数据保存到磁盘上。</li><li>缺页处理程序更新 PTE。</li><li>缺页处理程序结束，再回去执行上一条指令（导致缺页异常的那个指令，也就是 MOV 指令）。这次肯定命中了</li></ol><p>内存命中率：<br>命中率，这是衡量内存管理程序好坏的一个很重要的指标 在 n 次内存访问中，出现命中的次数是 m  那么 m &#x2F; n * 100% 就表示命中率<br>如果物理内存不足了，数据会在主存和磁盘之间频繁交换，命中率很低，性能出现急剧下降，我们称这种现象叫内存颠簸。这时你会发现系统的 swap 空间利用率开始增高， CPU 利用率中 iowait 占比开始增高。<br>大多数情况下，只要物理内存够用，页命中率不会非常低，不会出现内存颠簸的情况。因为大多数程序都有一个特点，就是局部性</p><p>局部性就是说被引用过一次的存储器位置，很可能在后续再被引用多次；而且在该位置附近的其他位置，也很可能会在后续一段时间内被引用</p><p>CPU Cache<br>主存与存储器之间以 page（通常是 4K） 为单位进行交换，cache 与 主存之间是以 cache line（通常 64 byte） 为单位交换的。<br>￼<br>￼<img src="/img/storage5.png"></p><p>程序内存布局<br>￼<br>￼<img src="/img/storage5.png"></p><p>text 段：存储程序的二进制指令，及其他的一些静态内容<br>data 段：用来存储已被初始化的全局变量。比如常量（const）<br>bss 段：用来存放未被初始化的全局变量。和 .data 段一样都属于静态分配，在这里面的变量数据在编译就确定了大小，不释放。<br>heap 段：堆空间，用于动态分配，C 语言中 malloc 和 free 操作的内存就在这里；Go 语言主要靠 GC 自动管理这部分。<br>stack 段：栈空间，主要用于函数调用时存储临时变量的。这部分的内存是自动分配自动释放的。</p><p>栈空间是通过压栈出栈方式自动分配释放的，由系统管理，使用起来高效无感知。<br>堆空间是用以动态分配的，由程序自己管理分配和释放。Go 语言虽然可以帮我们自动管理分配和释放，但是代价也是很高的。</p><p>CPU Cache 层面的低命中率导致的是程序运行缓慢，内存层面的低命中率会出现内存颠簸，</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;可以把内存看成一个数组，每个数组元素的大小是 1B，也就是 8 位(bit)。CPU 通过内存地址来获取内存中的数据，内存地址可以看做成数组的游标（index）&lt;/p&gt;
&lt;p&gt;￼&lt;img src=&quot;/img/storage1.png&quot;&gt;&lt;br&gt;￼&lt;br&gt;CPU 在执行指令的</summary>
      
    
    
    
    <category term="Golang" scheme="http://zhangming1994.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://zhangming1994.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>常见并发模型</title>
    <link href="http://zhangming1994.github.io/2023/06/18/%E5%B8%B8%E8%A7%81%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"/>
    <id>http://zhangming1994.github.io/2023/06/18/%E5%B8%B8%E8%A7%81%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/</id>
    <published>2023-06-18T06:25:29.000Z</published>
    <updated>2023-08-24T03:36:10.141Z</updated>
    
    <content type="html"><![CDATA[<h3 id="常见的并发模型-Fork-x2F-Join-Reactor-Proactor-Actor-CSP"><a href="#常见的并发模型-Fork-x2F-Join-Reactor-Proactor-Actor-CSP" class="headerlink" title="常见的并发模型[Fork&#x2F;Join   Reactor  Proactor   Actor  CSP]"></a>常见的并发模型[Fork&#x2F;Join   Reactor  Proactor   Actor  CSP]</h3><p>并发和并行都是相对于进程和线程来说的，并发是指一个或者若干个CPU对多个进程或者线程之间进行多路复用 就是cpu轮着执行多个任务 每个任务执行一段时间 并行则是指多个进程或者线程同一时刻被执行 是真正意义的同时执行 必须多个cpu的支持 </p><p>如果 对于并发来说 是线程一执行一段时间 二执行一段时间 三再执行一段时间 没个线程轮流的到cpu的执行时间 这种情况只需要一个cpu就可以实现 对于并行来说 线程一二三是同时执行 需要三个cpu ，当然 并发和并行都提升了cpu的资源利用效率<br>￼<br><img src="/img/golang/concurrency1.png"></p><h4 id="关于并发模型"><a href="#关于并发模型" class="headerlink" title="关于并发模型"></a>关于并发模型</h4><p>拥有多个cpu的现代计算机 依靠并发并行机制能更快的执行任务 但是如何通过并发并行来执行一个任务也有多种不同的方式 就是不同的并发模型, 不同的并发模型对任务的拆分也是不同的 线程之间的通信方式也是不同的, 由于并发模型规定了任务描述 执行方式和线程协作等的总体框架 所以并发模型设计 需要考虑 如简化对任务的描述 让并发高效 让开发人员更加方便实现并发 </p><p>任务模型:<br>￼<br><img src="/img/golang/2concurrency.png"></p><p>从进程与线程角度</p><p> 对于并发模型 如果我们从进程和线程的角度来看 主要有三种映射模式</p><ol><li>单进程-多线程</li><li>多进程-单线程</li><li>多进程-多线程<br>一般来说 进程的颗粒度大而且占用资源多 线程则是轻量级的 颗粒度小</li></ol><p>单进程-多线程<br>这种映射模式是指一个进程包含多个线程来执行任务 这是最常见的模式 一般来说 当线程数量少于cpu个数的时候 一个cpu对应一个线程 提高cpu的使用率 还有 多个线程共享进程内部资源 需要考虑线程安全问题 </p><p>￼<img src="/img/golang/3concurrency.png"></p><p>多进程-单线程<br>这种映射模式是指多个进程共同执行处理任务 每个进程内部只有一个线程 也就是程序启动之后 主进程创建多个子进程 每个字进程对应一个线程 这种模式下不存在线程安全问题 因为每个线程之间相互隔离 进程内部只有一个线程不存在共享内存问题</p><p>￼<br>￼<img src="/img/golang/4concurrency.png"></p><p>多进程-多线程<br>这个模式结合了前面两种模式 多个进程共同执行任务 每个进程包含多个线程 一个进程最多能够包含的线程数量是有限的 包含太多也可能导致性能下降 这时候就引入多个进程 就是多进程多线程模式 这种模式也需要考虑线程安全问题 进程和线程切换 一般认为这种模式增加了并发处理能力 特别是对于IO密集任务 但是更多的上下文切换 所以对cpu密集型任务处理能力不一定更高 </p><p>￼<br>￼<br>￼<img src="/img/golang/concurrency5.png"></p><p>无状态的并发并行<br>为了使用并行并发机制 我们会把大任务拆分成小任务 当我们拆分后的任务不涉及共享状态的时候 无状态也就代表多个进程和线程不需要访问共享数据 这时候并发并行就简单 不需要考虑线程安全问题 </p><p>￼￼<br>￼<img src="/img/golang/concurrency6.png"></p><p>共享状态问题<br>相对于无状态 并发并行的时候更多的是需要访问共享数据的情况 这个时候就存在共享状态问题 最常见的就是共享数据保存在内存当中 当然也可能保存在数据库或者其他存储系统上 一旦涉及到共享状态问题 就会涉及到竞争条件 死锁和并发问题 而且对共享状态的不同访问策略也可能影响执行的结果  而且 数据从内存到cpu中间会经历高速缓存和寄存器 这就扯出了数据可见性的问题 </p><p>上面是并发过程中多个线程会访问共享状态，而下面是并行过程中多个线程访问共享状态<br>￼<br>￼<br>￼<img src="/img/golang/concurrency7.png"></p><h4 id="并发模型设计"><a href="#并发模型设计" class="headerlink" title="并发模型设计"></a>并发模型设计</h4><p>之前说并发模型设计需要考虑的主体是cpu和任务 并发模型则是规定了任务描述 执行方式和线程协作的整体框架 </p><h4 id="Fork-x2F-Join模型"><a href="#Fork-x2F-Join模型" class="headerlink" title="Fork&#x2F;Join模型"></a>Fork&#x2F;Join模型</h4><p>这个模型其实就是一种分治思想 将任务不断分解成小的任务 执行完成之后将任务结果汇总 Fork操作就是分割任务 Join操作就是合并结果 其实车不多就是和合并排序的做法 相似</p><p>就像这个图 任务-1是总任务 fork分割 不断分割 ，然后分割的任务执行完成又join操作将任务结果一层层的向上传递 最终汇总为总任务的最终结果<br>￼<br>￼<br>￼<img src="/img/golang/concurrency8.png"></p><h4 id="Reactor模型"><a href="#Reactor模型" class="headerlink" title="Reactor模型"></a>Reactor模型</h4><p>是一种服务器端的模型 能够处理多个客户端并发请求访问 需要非阻塞机制的支持 Reactor模型将服务器端的整个处理过程分成若干事件 然后事件分发器会检测事件并将事件分发给相应的处理器处理 每个处理器仅仅负责自己的事情 而且要让所有的处理器都不产生阻塞 理想状态下每个事件处理器都能充分利用cpu</p><p>如图 若干客户端访问服务器 reactor事件分发器检测事件并将各种事件分发到对应的处理器处理 这个过程中如果有带处理的时间存在 就可以让reactor线程不断往下执行 而不会阻塞在一个地方 所以效率高<br>￼<br>￼<br>￼<img src="/img/golang/concurrency9.png"></p><h4 id="Proactor模型"><a href="#Proactor模型" class="headerlink" title="Proactor模型"></a>Proactor模型</h4><p>也是基于事件分发机制 但是Recator模型需要自己检测接收读写事件  一旦检测到可接受可读可写的事件就分发到各类处理器 但是Proactor模型是将分发器注册到操作系统内核 内核一旦完成某类事件就通知分发器 然后分发器再分发到各类处理器上&#x2F; 两者最大的不同是对IO的操作方式 Reactor是基于应用层发起的同步IO操作 但是Proactor是基于内核的异步IO操作 ，应用层先注册到内核并由内核负责事件通知 </p><p>首先应用层创建分发器Dispatcher并且注册到内核异步IO处理器中间 它能感知已经完成接收操作 已完成读操作 已完成写操作等事件<br>然后当有相应事件发生时内核会通知分发器 进而调用对应的处理Handler进行处理 如果Handler需要读写则可以直接对内核缓冲区进行操作 此时数据肯定是准备好的<br>￼<br>￼<br>￼<img src="/img/golang/concurrency10.png"></p><h4 id="Actor模型"><a href="#Actor模型" class="headerlink" title="Actor模型"></a>Actor模型</h4><p>该模型实际提供了一种更高层次的并发语义 通过该模型我们可以通过Actor实体概念来进行并发编程 这些Actor之间通过邮箱传递消息 简单来说<br>就是每个Actor里面都有自己的状态 行为和邮箱 接收到消息后会执行相应的行为进行逻辑处理 然后最重要的是Actor之间是不共享状态的<br>Actor模型出现之后 就不必接触多线程和线程池之类的基础概念 只需要将重心放在逻辑处理和消息传递上面  这是一种简化并发编程的方式  Actor通过不共享状态和消息传递来屏蔽这些复杂的问题 </p><p>实际上 任何物体都可以抽象为Actor 每个actor都有自己的状态 行为和邮箱 由于Actor之间完全独立 切状态不共享 所以必须通过邮箱来传递消息 每个Actor实际上可以看成是一个轻量级的线程 所以每个Actor最多同时进行一个工作 然后还有个很重要的 消息的传递是异步并且消息不可变<br>￼<br>￼<br>￼<img src="/img/golang/concurrency11.png"></p><h4 id="CSP模型"><a href="#CSP模型" class="headerlink" title="CSP模型"></a>CSP模型</h4><p>Csp模型就是通信顺序进程 看起来和Actor有点像 也是通过消息传递避免并发过程中的锁和同步的问题 从而简化并发编程  CSP模型主要有Processor和Channel两个概念 Processor表示执行任务顺序单元 Channel就是消息交互通道 可以传递数据消息  每个Processor之间相互独立<br>通过channel来通信 Actor模型中间每个Actor包含一个邮箱 是强耦合，但是CSP模型中间 Processor不包含Channel 他们之间是相互解耦的 </p><p>￼<br>￼<img src="/img/golang/concurrency12.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;常见的并发模型-Fork-x2F-Join-Reactor-Proactor-Actor-CSP&quot;&gt;&lt;a href=&quot;#常见的并发模型-Fork-x2F-Join-Reactor-Proactor-Actor-CSP&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="基础知识" scheme="http://zhangming1994.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="博客阅读 并发基础" scheme="http://zhangming1994.github.io/tags/%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB-%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>关系型数据库的瓶颈和优化</title>
    <link href="http://zhangming1994.github.io/2023/06/17/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%93%B6%E9%A2%88%E5%92%8C%E4%BC%98%E5%8C%96/"/>
    <id>http://zhangming1994.github.io/2023/06/17/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%93%B6%E9%A2%88%E5%92%8C%E4%BC%98%E5%8C%96/</id>
    <published>2023-06-17T13:28:53.000Z</published>
    <updated>2023-08-24T03:34:37.417Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据库分类"><a href="#数据库分类" class="headerlink" title="数据库分类"></a>数据库分类</h2><pre><code>数据库大致可以分为传统的关系型数据库 mysql oracle sqlserver postgresql等</code></pre><p>非关系型数据库 hbase(列式数据库) mongodb 文档型数据库 redis 高性能kv存储 lucene 搜索引擎等</p><p>数据库查询开销</p><p>￼<img src="/img/golang/1.png"></p><p>这个中间耗时操作有 建立TCP链接 生成执行计划 开表 从磁盘扫描数据 关闭链接</p><p>在mysql中间 主键查询是最为高效的一类查询 </p><p>索引字段如果太长 会导致order by无法在内存中见完成排序 使用mysql磁盘排序 并没有使用索引的排序</p><p>在mysql中间 数据按照页的方式来组织 默认大小16KB 包括页头 页尾 中间是记录<br>如果表中间存在大字段 达到了甚至超过了单页的大小 这个时候db就会新开一个数据页 当前页通过指针指向该页 一页不够 就会不断增加数据页直到可以存下为止 那么这个时候查询开销是很大的  严重的时候导致热页换出 引起系统抖动 ， </p><p>用了缓存 可能会有 缓存命中 缓存穿透 缓存失效 缓存一致性问题 </p><p>读写分离的原理就是将数据库读写操作分散到不同的节点上 </p><p>￼<img src="/img/golang/2.png"></p><ol><li>数据库服务器搭建主从集群 主负责写操作 从负责读操作  主复制将数据同步到从<br>引入读写分离之后 可能导致 主从复制延迟 分配机制问题</li></ol><p>主从复制延迟可能达到秒级别 如果数据量大 可能达到分钟级别<br>读写操作区分 访问不同数据库 一般有两种方式： 程序代码封装 或者 中间件封装<br>程序代码封装：<br>￼<br><img src="/img/golang/3.png"></p><p>这个做法无法多语言通用 主从切换 需要手动修改配置 </p><p>中间件封装：<br>地理一套系统出来 实现读写分离和数据库服务器连接的管理 中间件对业务服务器提供sql兼容的协议 业务服务器无需自己进行读写分离 </p><p>￼<img src="/img/golang/4.png"></p><p>读写分离 分散了读写的压力 但是没有分散存储的压力 当数据量上来之后 单台数据库服务器的存储能力就会变成瓶颈 读写能力下降 数据文件备份和恢复困难</p><p>垂直分表： 将表中间不常用的占用大量空间的列拆分出去 代价是操作表的数量增加<br>水平拆分： 适合行数较大的表 会导致更多的复杂度 join count等 </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;数据库分类&quot;&gt;&lt;a href=&quot;#数据库分类&quot; class=&quot;headerlink&quot; title=&quot;数据库分类&quot;&gt;&lt;/a&gt;数据库分类&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;数据库大致可以分为传统的关系型数据库 mysql oracle sqlserver postgres</summary>
      
    
    
    
    <category term="数据库" scheme="http://zhangming1994.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="数据库" scheme="http://zhangming1994.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://zhangming1994.github.io/2022/08/17/hello-world/"/>
    <id>http://zhangming1994.github.io/2022/08/17/hello-world/</id>
    <published>2022-08-17T09:23:37.000Z</published>
    <updated>2023-08-24T03:34:33.694Z</updated>
    
    <content type="html"><![CDATA[<h3 id="生成新的文章"><a href="#生成新的文章" class="headerlink" title="生成新的文章"></a>生成新的文章</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>更多: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>更多: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="生成"><a href="#生成" class="headerlink" title="生成"></a>生成</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>更多: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>更多: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><h3 id="常用命令-注意以下命令需要切换到blog文件夹-cd-blog-执行"><a href="#常用命令-注意以下命令需要切换到blog文件夹-cd-blog-执行" class="headerlink" title="常用命令[注意以下命令需要切换到blog文件夹(cd blog)执行]"></a>常用命令[注意以下命令需要切换到blog文件夹(cd blog)执行]</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hexo n &quot;文章名称&quot;  =&gt; hexo new &quot;文章名称&quot;  #这两个都是创建新文章，前者是简写模式，下同，new后面加一个draft可以生成草稿</span><br><span class="line">hexo p  =&gt; hexo publish  # 发布草稿</span><br><span class="line">hexo g  =&gt; hexo generate  # 生成</span><br><span class="line">hexo s  =&gt; hexo server  # 启动服务预览</span><br><span class="line">hexo d  =&gt; hexo deploy  # 部署</span><br><span class="line"> </span><br><span class="line">hexo server   # Hexo 会监视文件变动并自动更新，无须重启服务器。</span><br><span class="line">hexo server -s   # 静态模式</span><br><span class="line">hexo server -p 5000   #更 改端口</span><br><span class="line">hexo server -i 192.168.1.1   # 自定义IP</span><br><span class="line">hexo clean   # 清除缓存，网页正常情况下可以忽略此条命令</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;生成新的文章&quot;&gt;&lt;a href=&quot;#生成新的文章&quot; class=&quot;headerlink&quot; title=&quot;生成新的文章&quot;&gt;&lt;/a&gt;生成新的文章&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutt</summary>
      
    
    
    
    
  </entry>
  
</feed>
